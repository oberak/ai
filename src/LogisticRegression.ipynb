{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticRegression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSdowOc3J5ba",
        "outputId": "a7517114-06ca-4538-fb22-478e979d304e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Importing necessary modules\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 502,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 502
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-g1RzpaKXU3"
      },
      "source": [
        "# preparing training data\n",
        "x_train = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
        "y_train = [[0], [0], [0], [1], [1], [1]]"
      ],
      "execution_count": 503,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3urp_KZPKbAQ",
        "outputId": "803addf9-21f9-4268-f00d-68beafa9bfdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Initializing weights and biases\n",
        "W = tf.Variable(tf.random.normal([2, 1]), name='weight')\n",
        "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
        "\n",
        "\n",
        "W.dtype"
      ],
      "execution_count": 504,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tf.float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 504
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_bReinmL_wF"
      },
      "source": [
        "# Hypothesis: Logistic regression H(x) = Wx + b\n",
        "def logistic_regression(X):\n",
        "  return tf.nn.sigmoid(tf.matmul(tf.cast(X, tf.float32), W) + b)\n",
        "  #return tf.divide(1., 1. + tf.exp(tf.matmul(x, W)+b)) # cross entropy"
      ],
      "execution_count": 505,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guo4cn_xMuHS"
      },
      "source": [
        "# Cost(loss) function: Cross entropy =  -1/m * Sum( y*log(H(x)) + (1-y) * log(1 - H(x)) )\n",
        "def cross_entropy(predicted, real):\n",
        "  #predicted, real = np.array(predicted), np.array(real) # convert to numpy\n",
        "  return -tf.reduce_mean(real * tf.math.log(predicted) + ( 1 - np.array(real)) * tf.math.log(1 - predicted))\n",
        "  #return -tf.reduce_mean(real * tf.math.log(predicted) + ( 1. - np.array(real)) * tf.math.log(1. - np.array(predicted)))\n",
        "  #return tf.reduce_mean(-tf.reduce_sum(real * tf.math.log(predicted)))"
      ],
      "execution_count": 506,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JisIyCy9PAe3"
      },
      "source": [
        "# Optimizer: Gradient descent W = W - a(dy / dW), b = b - a(dy / db)\n",
        "def gd(x, y, learning_rate):\n",
        "  # get gradient\n",
        "  with tf.GradientTape(persistent=True) as g:\n",
        "    pred = logistic_regression(x)\n",
        "    loss = cross_entropy(pred, y)\n",
        "\n",
        "  dy_dw = g.gradient(loss, W)\n",
        "  dy_db = g.gradient(loss, b)\n",
        "  #print('loss', loss.numpy())\n",
        " \n",
        "  W.assign_sub(learning_rate * dy_dw)\n",
        "  b.assign_sub(learning_rate * dy_db)"
      ],
      "execution_count": 507,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVqDR5plP7U6"
      },
      "source": [
        "# training function\n",
        "def train(x, y, learning_rate=0.01, epoch=200):\n",
        "  for i in range(epoch):\n",
        "    gd(x, y, learning_rate)"
      ],
      "execution_count": 508,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUtbtvNCP_QC",
        "outputId": "8b5fffb1-77f1-4448-ace7-0944dc02b74d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# train\n",
        "train(x_train, y_train, 0.02, 4000)\n",
        "print('Model H(x) = X * {} + {}'.format(W.numpy(), b.numpy()[0])) # W=2, b=0"
      ],
      "execution_count": 509,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model H(x) = X * [[1.3584164 ]\n",
            " [0.18957089]] + -4.856379985809326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRyvHQNJoiL5",
        "outputId": "9182c6f1-7a8e-4bbe-9aed-6998e8032ea2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# check prediction and accuracy\n",
        "hypothesis = logistic_regression(x_train)\n",
        "pred = tf.cast(hypothesis>0.5, dtype=tf.int16)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(pred, y_train), tf.float32))\n",
        "print('hypothesis:', hypothesis.numpy())\n",
        "print('pred:', pred.numpy())\n",
        "print('accuracy:', accuracy.numpy())"
      ],
      "execution_count": 510,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hypothesis: [[0.04233748]\n",
            " [0.17209744]\n",
            " [0.35627705]\n",
            " [0.7587793 ]\n",
            " [0.92445076]\n",
            " [0.9752353 ]]\n",
            "pred: [[0]\n",
            " [0]\n",
            " [0]\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}